from app.api.routers.langchain_multipdf_router import enrich_question
import streamlit as st
import requests
import os

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="üìÑ MultiPDF RAG - Langchain - FAISS - Spacy", layout="wide")

# Inicializar el historial de chat si no existe
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Sidebar para configuraci√≥n de Azure OpenAI
st.sidebar.title("‚öôÔ∏è Configuraci√≥n Azure OpenAI")

api_key = st.sidebar.text_input("Ingrese su AZURE_OPENAI_API_KEY:", type="password")
azure_deployment = st.sidebar.text_input("Ingrese su AZURE_OPENAI_DEPLOYMENT_NAME:", type="default")
azure_endpoint = st.sidebar.text_input("Ingrese su AZURE_OPENAI_ENDPOINT:", type="default")
api_version = st.sidebar.text_input("Ingrese su AZURE_OPENAI_API_VERSION:", value="2024-08-01-preview")

# Guardar configuraciones en variables de entorno
if st.sidebar.button("Guardar Configuraci√≥n"):
    os.environ["AZURE_OPENAI_API_KEY"] = api_key
    os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"] = azure_deployment
    os.environ["AZURE_OPENAI_ENDPOINT"] = azure_endpoint
    os.environ["AZURE_OPENAI_API_VERSION"] = api_version
    st.sidebar.success("‚úÖ Configuraci√≥n guardada con √©xito.")
    st.rerun()  # Forzar una recarga para aplicar las variables de entorno

# Configuraci√≥n de la interfaz principal
st.title("üìÑ MultiPDF RAG - Langchain - FAISS")
st.write("Sube tus PDFs y realiza consultas a trav√©s de una interfaz amigable.")

# Secci√≥n para mostrar archivos disponibles
st.header("üìÇ Archivos Disponibles")

# Obtener la lista de archivos desde el backend
def fetch_pdf_files():
    with st.spinner("Cargando archivos disponibles..."):
        response = requests.get("http://localhost:8000/list-pdfs/")
    return response

response = fetch_pdf_files()

if response.status_code == 200:
    pdf_files = response.json().get("pdf_files", [])
    if pdf_files:
        st.write("Archivos disponibles:")
        for pdf in pdf_files:
            # Ajustar las proporciones de las columnas
            col1, col2 = st.columns([0.85, 0.15])
            
            with col1:
                st.write(f"üìÑ {pdf}")
            
            with col2:
                # Alinear el bot√≥n verticalmente al centro
                st.write("")  # Espacio para centrar el bot√≥n
                if st.button("üóëÔ∏è Eliminar", key=f"delete_{pdf}"):
                    delete_response = requests.delete("http://localhost:8000/delete-pdf/", params={"filename": pdf})
                    if delete_response.status_code == 200:
                        st.success(f"‚úÖ Archivo '{pdf}' eliminado con √©xito.")
                        st.rerun()
                    else:
                        st.error(f"‚ùå Error al eliminar el archivo: {delete_response.text}")
    else:
        st.write("No hay archivos disponibles.")
else:
    st.error(f"‚ùå Error al obtener la lista de archivos: {response.text}")
    
# Secci√≥n para subir PDFs
st.header("üîº Subir PDFs")
uploaded_files = st.file_uploader("Selecciona uno o varios archivos PDF", type="pdf", accept_multiple_files=True)

if st.button("Procesar PDFs"):
    if uploaded_files:
        files_to_send = [("files", (file.name, file, "application/pdf")) for file in uploaded_files]

        with st.spinner("Procesando PDFs..."):
            response = requests.post("http://localhost:8000/upload/", files=files_to_send)

        if response.status_code == 200:
            st.success("‚úÖ PDFs procesados y base de datos vectorial creada con √©xito.")
            st.rerun()
        else:
            st.error(f"‚ùå Error al procesar PDFs: {response.text}")
    else:
        st.warning("‚ö†Ô∏è Por favor, sube al menos un archivo PDF.")

# Secci√≥n para hacer consultas tipo chat
st.header("üí¨ Chat con los PDFs")

# Entrada de usuario para nuevas preguntas
user_question = st.chat_input("Escribe tu pregunta sobre los PDFs procesados:")

if user_question:
    # Enriquecer la consulta del usuario
    enriched_question = enrich_question(user_question, st.session_state.chat_history)

    # Agregar la pregunta del usuario al historial de chat
    st.session_state.chat_history.append({"role": "user", "content": user_question})

    # Mostrar la pregunta del usuario en el chat
    with st.chat_message("user"):
        st.markdown(user_question)

    # Mostrar la consulta enriquecida (para depuraci√≥n)
    with st.expander("üîç Consulta Enriquecida"):
        st.markdown(enriched_question)

    # Enviar la pregunta enriquecida a la API de FastAPI
    with st.spinner("Buscando respuesta..."):
        response = requests.post("http://localhost:8000/query/", data={"question": enriched_question})

    if response.status_code == 200:
        answer = response.json().get("answer", "No se encontr√≥ una respuesta.")
    else:
        answer = f"‚ùå Error al consultar la API: {response.text}"

    # Agregar la respuesta al historial de chat
    st.session_state.chat_history.append({"role": "assistant", "content": answer})

    # Mostrar la respuesta del asistente en el chat
    with st.chat_message("assistant"):
        st.markdown(answer)

# Mostrar historial de chat
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


